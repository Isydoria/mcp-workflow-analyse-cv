"""
MCP Server for Analyse-CV using fastapi-mcp
Generated by LightOn Workflow Builder

This server exposes the workflow via proper MCP protocol for integration with:
- LightOn Paradigm (MCP integration)
- Claude Desktop
- Any MCP-compatible client

Usage:
    python -m mcp_server --port 8080
"""

import argparse
import asyncio
import logging
import os
from typing import List, Optional

from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from fastapi_mcp import FastApiMCP
from pydantic import BaseModel, Field
import uvicorn

from workflow import WorkflowExecutor
from paradigm_client import ParadigmClient

# Load environment variables from .env file
load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize FastAPI app
app = FastAPI(
    title="Analyse-CV MCP Server",
    description="Analyse et compare automatiquement 5 CV par rapport à une fiche de poste, en évaluant chaque candidat selon des critères pondérés et génère un rapport professionnel avec scores et recommandations.",
    version="1.0.0"
)

# Initialize MCP server (must be done before defining tools)
mcp = FastApiMCP(app)

# Server configuration
PARADIGM_API_KEY = os.getenv("PARADIGM_API_KEY")
PARADIGM_BASE_URL = os.getenv("PARADIGM_BASE_URL", "https://paradigm.lighton.ai")


# Request/Response models
class AnalyseRequest(BaseModel):
    """Request model for CV analysis"""
    file_paths: Optional[List[str]] = Field(
        None,
        description="Chemins complets des fichiers locaux a analyser (ex: C:\\Documents\\cv.pdf)"
    )
    file_ids: Optional[List[int]] = Field(
        None,
        description="IDs des documents Paradigm a analyser"
    )
    query: Optional[str] = Field(
        None,
        description="Question ou demande d'analyse (optionnel)"
    )

    def model_post_init(self, __context) -> None:
        """Validate that at least one file input method is provided"""
        if not self.file_paths and not self.file_ids:
            raise ValueError("Either file_paths or file_ids must be provided")


class AnalyseResponse(BaseModel):
    """Response model for CV analysis"""
    result: dict = Field(..., description="Analysis results")
    status: str = Field(..., description="Execution status")


# Helper function for resolving Paradigm filenames to IDs
async def _resolve_paradigm_filenames(
    paradigm_client: ParadigmClient,
    filenames: List[str]
) -> List[int]:
    """
    Resolve Paradigm document filenames to their IDs by searching in the user's workspace.

    This function searches for documents by exact filename match.

    Args:
        paradigm_client: Initialized Paradigm client
        filenames: List of document filenames to resolve

    Returns:
        List of resolved file IDs

    Raises:
        Exception: If any filename cannot be resolved
    """
    file_ids = []

    for filename in filenames:
        try:
            # Use document search to find the file
            # Search for exact filename in user's private collection
            search_results = await paradigm_client.document_search(
                query=f"filename:{filename}",
                collection='private',
                n=1  # We only need the best match
            )

            # Extract file ID from search results
            if search_results and 'chunks' in search_results and len(search_results['chunks']) > 0:
                chunk = search_results['chunks'][0]
                file_id = chunk.get('file_id') or chunk.get('id')
                if file_id:
                    file_ids.append(int(file_id))
                    logger.info(f"✅ Resolved '{filename}' to file ID: {file_id}")
                else:
                    raise Exception(f"Could not extract file ID for: {filename}")
            else:
                raise Exception(f"Document not found: {filename}")

        except Exception as e:
            logger.error(f"❌ Failed to resolve filename '{filename}': {str(e)}")
            raise Exception(f"Failed to resolve document '{filename}': {str(e)}")

    return file_ids


@app.post("/analyse_cv", response_model=AnalyseResponse, operation_id="analyse_cv")
async def analyse_cv(request: AnalyseRequest) -> AnalyseResponse:
    """
    Analyse and compare CVs against a job description.

    This endpoint executes a complete workflow using the LightOn Paradigm API.
    """
    try:
        # Validate Paradigm API key
        if not PARADIGM_API_KEY:
            raise HTTPException(
                status_code=500,
                detail="PARADIGM_API_KEY not configured on server"
            )

        # Initialize Paradigm client
        paradigm_client = ParadigmClient(
            api_key=PARADIGM_API_KEY,
            base_url=PARADIGM_BASE_URL
        )

        # Determine input mode and handle file resolution
        file_ids_to_use = []

        if request.file_ids:
            # Direct file IDs provided
            logger.info(f"Using {len(request.file_ids)} provided file IDs")
            file_ids_to_use = request.file_ids

        elif request.file_paths:
            # Check if file_paths are actually Paradigm document names (no path separators)
            are_paradigm_names = all('/' not in fp and '\\' not in fp for fp in request.file_paths)

            if are_paradigm_names:
                # These are Paradigm document names, search for them
                logger.info(f"Detected {len(request.file_paths)} Paradigm document names, searching for IDs...")
                file_ids_to_use = await _resolve_paradigm_filenames(
                    paradigm_client,
                    request.file_paths
                )
                logger.info(f"Resolved to file IDs: {file_ids_to_use}")
            else:
                # These are actual file paths, pass them as-is
                logger.info(f"Using {len(request.file_paths)} local file paths")

        # Initialize workflow executor
        executor = WorkflowExecutor(paradigm_client)

        # Execute workflow with appropriate parameters
        exec_params = {"query": request.query}

        if file_ids_to_use:
            exec_params["file_ids"] = file_ids_to_use
        elif request.file_paths:
            exec_params["file_paths"] = request.file_paths

        result = await executor.execute(**exec_params)

        logger.info("Workflow execution completed successfully")

        return AnalyseResponse(
            result=result,
            status="success"
        )

    except Exception as e:
        logger.error(f"Workflow execution failed: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Workflow execution failed: {str(e)}"
        )


# Health check endpoint
@app.get("/health")
async def health():
    """Health check endpoint"""
    return {"status": "healthy"}


# Re-register all tools after defining endpoints
mcp.setup_server()

# Mount MCP HTTP endpoint
mcp.mount_http()

logger.info("MCP server mounted at /mcp endpoint")
logger.info(f"Paradigm API URL: {PARADIGM_BASE_URL}")
logger.info("Server is ready to accept MCP connections")


def main():
    """Main entry point for MCP server"""
    parser = argparse.ArgumentParser(description="MCP Server for Analyse-CV")
    parser.add_argument(
        "--port",
        type=int,
        default=8080,
        help="Port to listen on (default: 8080)"
    )
    parser.add_argument(
        "--host",
        type=str,
        default="0.0.0.0",
        help="Host to bind to (default: 0.0.0.0)"
    )

    args = parser.parse_args()

    logger.info(f"Starting MCP Server for Analyse-CV")
    logger.info(f"Host: {args.host}")
    logger.info(f"Port: {args.port}")
    logger.info(f"MCP endpoint will be available at: http://{args.host}:{args.port}/mcp")

    uvicorn.run(
        app,
        host=args.host,
        port=args.port,
        log_level="info"
    )


if __name__ == "__main__":
    main()
